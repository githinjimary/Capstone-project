{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4499673f",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting dlib\n",
      "  Using cached dlib-19.23.1.tar.gz (7.4 MB)\n",
      "Building wheels for collected packages: dlib\n",
      "  Building wheel for dlib (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for dlib: filename=dlib-19.23.1-cp38-cp38-linux_x86_64.whl size=3990651 sha256=c3e43585473661c6b24c4b032bb883893a9677ca7be8647cdf300c36d8b06866\n",
      "  Stored in directory: /home/mary/.cache/pip/wheels/3a/ac/73/b4a0ecae4672035801b9d8a9e83eb31049bd438e7ad6ce4852\n",
      "Successfully built dlib\n",
      "Installing collected packages: dlib\n",
      "Successfully installed dlib-19.23.1\n"
     ]
    }
   ],
   "source": [
    "#install if not available\n",
    "\n",
    "!pip install dlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "624dc1c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: face_recognition in ./anaconda3/lib/python3.8/site-packages (1.3.0)\n",
      "Requirement already satisfied: dlib>=19.7 in ./anaconda3/lib/python3.8/site-packages (from face_recognition) (19.23.1)\n",
      "Collecting face-recognition-models>=0.3.0\n",
      "  Downloading face_recognition_models-0.3.0.tar.gz (100.1 MB)\n",
      "\u001b[K     |████████████████████████████████| 100.1 MB 13 kB/s  eta 0:00:01   |█▊                              | 5.3 MB 271 kB/s eta 0:05:50     |██▋                             | 8.1 MB 187 kB/s eta 0:08:11     |████▉                           | 15.0 MB 273 kB/s eta 0:05:12     |█████▉                          | 18.2 MB 251 kB/s eta 0:05:27     |██████                          | 18.8 MB 129 kB/s eta 0:10:27     |███████▏                        | 22.5 MB 634 kB/s eta 0:02:03     |██████████▏                     | 31.9 MB 125 kB/s eta 0:09:03     |███████████▌                    | 35.9 MB 261 kB/s eta 0:04:06     |█████████████                   | 40.4 MB 547 kB/s eta 0:01:50     |███████████████▍                | 48.1 MB 263 kB/s eta 0:03:18     |████████████████▋               | 52.1 MB 447 kB/s eta 0:01:48     |█████████████████               | 53.4 MB 275 kB/s eta 0:02:50     |██████████████████▏             | 56.7 MB 246 kB/s eta 0:02:57     |████████████████████            | 62.9 MB 214 kB/s eta 0:02:54     |█████████████████████████████▊  | 93.1 MB 362 kB/s eta 0:00:20     |████████████████████████████████| 100.0 MB 168 kB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: Click>=6.0 in ./anaconda3/lib/python3.8/site-packages (from face_recognition) (7.1.2)\n",
      "Requirement already satisfied: numpy in ./anaconda3/lib/python3.8/site-packages (from face_recognition) (1.20.1)\n",
      "Requirement already satisfied: Pillow in ./anaconda3/lib/python3.8/site-packages (from face_recognition) (8.2.0)\n",
      "Building wheels for collected packages: face-recognition-models\n",
      "  Building wheel for face-recognition-models (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for face-recognition-models: filename=face_recognition_models-0.3.0-py2.py3-none-any.whl size=100566173 sha256=073d65da72ca2a4695940341ae18815c052c87d31e3520f7923acfe7599149d6\n",
      "  Stored in directory: /home/mary/.cache/pip/wheels/b4/4b/8f/751e99d45f089bdf366a7d3e5066db3c2b84a62e4377f534d7\n",
      "Successfully built face-recognition-models\n",
      "Installing collected packages: face-recognition-models\n",
      "Successfully installed face-recognition-models-0.3.0\n"
     ]
    }
   ],
   "source": [
    "!pip3 install face_recognition\n",
    "#pip install face_recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b725cec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "import cv2\n",
    "import numpy as np\n",
    "import face_recognition\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d84bab3",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load an image\n",
    "obamaimg = face_recognition.load_image_file('/home/mary/Downloads/obama.jpg')\n",
    "obama = cv2.cvtColor(obamaimg,cv2.COLOR_BGR2RGB)\n",
    "cv2.imshow('img',obama)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "8b59519e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.destroyAllWindows() \n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef671150",
   "metadata": {},
   "outputs": [],
   "source": [
    "obamaimg = face_recognition.load_image_file('/home/mary/Downloads/obama.jpg')\n",
    "obama = cv2.cvtColor(obamaimg,cv2.COLOR_BGR2RGB)\n",
    "#Finding face Location for drawing bounding boxes-------\n",
    "face = face_recognition.face_locations(obama)[0]\n",
    "copy = obama.copy()\n",
    "#-Drawing the Rectangle\n",
    "cv2.rectangle(copy, (face[3], face[0]),(face[1], face[2]), (255,0,255), 2)\n",
    "cv2.imshow('img',copy)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e87debc1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.destroyAllWindows() \n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14ef52a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#training \n",
    "train_OBAMA_encodings = face_recognition.face_encodings(obama)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001a4691",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test an image\n",
    "test = face_recognition.load_image_file('/home/mary/Downloads/obamaother.jpeg')\n",
    "test = cv2.cvtColor(test, cv2.COLOR_BGR2RGB)\n",
    "test_encode = face_recognition.face_encodings(test)[0]\n",
    "print(face_recognition.compare_faces([train_OBAMA_encodings],test_encode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "064c80af",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[True]\n"
     ]
    }
   ],
   "source": [
    "#test an older image\n",
    "test2 = face_recognition.load_image_file('/home/mary/Downloads/obamaold.jpeg')\n",
    "test2 = cv2.cvtColor(test2, cv2.COLOR_BGR2RGB)\n",
    "test2_encode = face_recognition.face_encodings(test2)[0]\n",
    "print(face_recognition.compare_faces([train_OBAMA_encodings],test2_encode))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "567e28c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[False]\n"
     ]
    }
   ],
   "source": [
    "# test an image of trump\n",
    "test3 = face_recognition.load_image_file('/home/mary/Downloads/trump.jpg')\n",
    "test3 = cv2.cvtColor(test3, cv2.COLOR_BGR2RGB)\n",
    "test3_encode = face_recognition.face_encodings(test3)[0]\n",
    "print(face_recognition.compare_faces([train_OBAMA_encodings],test3_encode))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2ea521ae",
   "metadata": {},
   "source": [
    "**Building a Face Recognition System**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aef04773",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing libraries. \n",
    "import cv2\n",
    "import face_recognition\n",
    "import os\n",
    "import numpy as np\n",
    "from datetime import datetime\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b176dbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/home/mary/Downloads/students_images'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b966e18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['uhuru_kenyatta.jpeg', 'Drake.jpg', 'MARY.jpg', 'OPRAH.jpg', 'obama.jpg', 'Ryan Reynolds.jpg', 'trump (1).jpg', 'Nicki Minaj.jpg']\n",
      "['uhuru_kenyatta', 'Drake', 'MARY', 'OPRAH', 'obama', 'Ryan Reynolds', 'trump (1)', 'Nicki Minaj']\n"
     ]
    }
   ],
   "source": [
    "#create a list to store person_name and image array\n",
    "images = []\n",
    "classNames = []\n",
    "mylist = os.listdir(path)\n",
    "print(mylist)\n",
    "for cl in mylist:\n",
    "    curImg = cv2.imread(f'{path}/{cl}')\n",
    "    images.append(curImg)\n",
    "    classNames.append(os.path.splitext(cl)[0])\n",
    "\n",
    "print(classNames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "990c34e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#create a function to encode all the train images and store them in a variable encoded_face_train.\n",
    "def findEncodings(images):\n",
    "    encodeList = []\n",
    "    for img in images:\n",
    "        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n",
    "        encoded_face = face_recognition.face_encodings(img)[0]\n",
    "        encodeList.append(encoded_face)\n",
    "    return encodeList\n",
    "encoded_face_train = findEncodings(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "03b56f7d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "print(len(encoded_face_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "8dbbef10",
   "metadata": {},
   "outputs": [],
   "source": [
    "#MARK ATTENDANCE\n",
    "def markAttendance(name):\n",
    "    with open('/home/mary/Documents/Attendance2.csv','r+') as f:\n",
    "        myDataList = f.readlines()\n",
    "        nameList = []\n",
    "        for line in myDataList:\n",
    "            entry = line.split(',')\n",
    "            nameList.append(entry[0])\n",
    "        if name not in nameList:\n",
    "            now = datetime.now()\n",
    "            dtstring = now.strftime('%H:%M:%S')\n",
    "            #date = now.strftime('%d-%B-%Y')\n",
    "            f.writelines(f'\\n{name},{dtstring}')\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "778c2df8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "mary\n",
      "2\n",
      "mary\n",
      "2\n",
      "mary\n",
      "2\n",
      "mary\n",
      "2\n",
      "mary\n",
      "2\n",
      "mary\n",
      "2\n",
      "mary\n",
      "2\n",
      "mary\n",
      "2\n",
      "mary\n",
      "2\n",
      "mary\n",
      "2\n",
      "mary\n",
      "2\n",
      "mary\n",
      "2\n",
      "mary\n",
      "2\n",
      "mary\n",
      "2\n",
      "mary\n",
      "2\n",
      "mary\n",
      "2\n",
      "mary\n",
      "2\n",
      "2\n",
      "mary\n",
      "2\n",
      "mary\n",
      "2\n",
      "mary\n",
      "2\n",
      "mary\n",
      "2\n",
      "mary\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cap  = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    success, img = cap.read()\n",
    "    imgS = cv2.resize(img, (0,0), None, 0.25,0.25) #imgS is small image\n",
    "    imgS = cv2.cvtColor(imgS, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    faces_in_frame = face_recognition.face_locations(imgS)\n",
    "    encoded_faces = face_recognition.face_encodings(imgS, faces_in_frame)\n",
    "    \n",
    "    for encode_face, faceloc in zip(encoded_faces,faces_in_frame):\n",
    "        matches = face_recognition.compare_faces(encoded_face_train, encode_face)\n",
    "        faceDist = face_recognition.face_distance(encoded_face_train, encode_face)\n",
    "        matchIndex = np.argmin(faceDist)\n",
    "        print(matchIndex)\n",
    "        if matches[matchIndex]:\n",
    "            name = classNames[matchIndex].upper().lower()\n",
    "            print(name)\n",
    "            y1,x2,y2,x1 = faceloc\n",
    "            # since we scaled down by 4 times\n",
    "            y1, x2,y2,x1 = y1*4,x2*4,y2*4,x1*4\n",
    "            cv2.rectangle(img,(x1,y1),(x2,y2),(0,255,0),2)\n",
    "            cv2.rectangle(img, (x1,y2-35),(x2,y2), (0,255,0), cv2.FILLED)\n",
    "            cv2.putText(img,name, (x1+6,y2-5), cv2.FONT_HERSHEY_COMPLEX,1,(255,255,255),2)\n",
    "            markAttendance(name)\n",
    "    cv2.imshow('webcam', img)\n",
    "    if cv2.waitKey(1) & 0xFF==ord('q'): # quit when 'q' is pressed\n",
    "        cap.release()\n",
    "        break\n",
    "        \n",
    "cv2.destroyAllWindows() \n",
    "cv2.waitKey(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c54cba3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Name,Time']\n",
      "[]\n",
      "[]\n",
      "['mary,13:55:06']\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "with open('/home/mary/Documents/Attendance2.csv', 'r') as file:\n",
    "    reader = csv.reader(file, delimiter = '\\t')\n",
    "    for row in reader:\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b466e51",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>mary</td>\n",
       "      <td>13:55:06</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Name      Time\n",
       "0  mary  13:55:06"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "P = pd.read_csv('/home/mary/Documents/Attendance2.csv')\n",
    "P"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "99d6849a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv2.destroyAllWindows() \n",
    "cv2.waitKey(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
